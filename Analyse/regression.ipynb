{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/riccardodandrea/Schreibtisch/Github/ReutersNOZ'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir(\"/home/riccardodandrea/Schreibtisch/Github/ReutersNOZ\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19043, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"reuters_articles_with_split.csv\")\n",
    "#df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topics    8666\n",
       "text         0\n",
       "split        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topics\"].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrekt anfang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature and Label sets\n",
    "X = df['text']\n",
    "y = df['topics']\n",
    "# train test split (66% train - 33% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print('Training Data :', X_train.shape)\n",
    "\n",
    "print('Testing Data : ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.predict(count_vect.transform([\"\"\"CRUDE OIL NETBACKS UP SHARPLY IN EUROPE, U.S.</TITLE>\n",
    "<DATELINE>    NEW YORK, April 9 - </DATELINE><BODY>Crude oil netback values in complex\n",
    "refineries rose sharply in Europe and firmed in the U.S. last\n",
    "Friday from the previous week but fell sharply in Singapore,\n",
    "according to calculations by Reuters Pipeline.\n",
    "    The firmer tone to refining margins in Europe and the U.S.\n",
    "relected higher prices for petroleum products, particularly\n",
    "gasoline, and support from crude oil prices.\n",
    "    Netback values for crude oil refined in Northern Europe\n",
    "rose substantially following strong gains in gasoline prices\n",
    "there. Brent is valued at 19.45 dlrs, up 56 cts a barrel or\n",
    "three pct from the previous week.\n",
    "    In the U.S. Gulf, sweet crudes rose in value by 14 cts to\n",
    "19.33 dlrs for West Texas Intermediate, up about 0.7 pct.\n",
    "    Sour grades in the U.S. Gulf showed an increase of 33 cts a\n",
    "barrel for Alaska North Slope, up 1.7 pct.\n",
    "    But netbacks for crude oil refined in Singapore fell\n",
    "sharply, down 15 cts to as much as 68 cts a barrel as ample\n",
    "distillate supplies weighed on petroleum product prices.\n",
    "    Attaka in Singapore is valued at 18.55 dlrs, a decline of\n",
    "68 cts a barrel or 3.5 pct from the previous week.\n",
    "    For refineries in the Mediterranean, netback values were\n",
    "mostly lower, with declines of seven to 14 cts. The value of\n",
    "Kuwait crude fell 14 cts to 18.37 dlrs, while Iranian Light\n",
    "fell 11 cts to 19.14 dlrs.\n",
    "    On the U.S. West Coast, netback values for ANS CIF L.A.\n",
    "also jumped sharply, up 40 cts a barrel or 2.2 pct to 18.82\n",
    "dlrs on higher gasoline prices.\"\"\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list(df[\"topics\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrekt ende"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 0.790\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Laden der CSV-Datei mit den Artikeln\n",
    "df = pd.read_csv(\"reuters_articles_with_split.csv\")\n",
    "df = df.dropna()\n",
    "# Features ausw√§hlen (Text) und Zielvariable (Topics)\n",
    "X = df[\"text\"]\n",
    "y = df[\"topics\"]\n",
    "\n",
    "# Trainingsdaten trennen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF-Vektorisierung der Texte (Text in numerische Vektoren umwandeln)\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')  # max_features setzt die Anzahl der Vektoren\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Modell trainieren\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Modell evaluieren\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Genauigkeit: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vorhergesagtes Thema: earn\n"
     ]
    }
   ],
   "source": [
    "# Beispieltext, den du vorhersagen m√∂chtest\n",
    "new_text = \"\"\"Oper shr 38 cts vs 1.84 dlrs\n",
    "    Oper net 973,000 vs 4,497,000\n",
    "    Nine mths\n",
    "    Oper shr 1.22 dlrs vs 1.31 dlrs\n",
    "    Oper net 3,133,000 vs 3,410,000\n",
    "    NOTE: Results exclude extraordinary gain from net loss\n",
    "carryforward of 672,000 dlrs or 27 cts in 1987 3rd qtr, 918,000\n",
    "dlrs 38 cts in 1986 3rd qtr, and 1,071,000 dlrs or 44 cts in\n",
    "1987 nine months. 1986 results include 5.1 mln dlr gain from\n",
    "termination of defined benefit pension plan.\"\"\"\n",
    "\n",
    "# Schritt 1: Text in denselben numerischen Vektor umwandeln, der f√ºr das Training verwendet wurde\n",
    "new_text_tfidf = vectorizer.transform([new_text])\n",
    "\n",
    "# Schritt 2: Vorhersage des Themas mit dem trainierten Modell\n",
    "predicted_topic = model.predict(new_text_tfidf)\n",
    "\n",
    "# Ausgabe des vorhergesagten Themas\n",
    "print(f\"Vorhergesagtes Thema: {predicted_topic[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(X_test_tfidf, y_test, model):\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=set(y_test), yticklabels=set(y_test))\n",
    "    plt.xlabel(\"Vorhergesagte Labels\")\n",
    "    plt.ylabel(\"Tats√§chliche Labels\")\n",
    "    plt.title(\"üìä Konfusionsmatrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Jetzt ausf√ºhren:\n",
    "plot_confusion_matrix(X_test_tfidf, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature and Label sets\n",
    "X_test_filtered = df[df['split'] == \"TEST\"]\n",
    "X_train_filtered = df[df['split'] == \"TRAIN\"]\n",
    "\n",
    "X_test = X_test_filtered.drop(columns=[\"topics\",\"split\"])\n",
    "X_train = X_train_filtered.drop(columns=[\"topics\",\"split\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_filtered = df[df[\"split\"]== \"TEST\"]\n",
    "y_train_filtered = df[df[\"split\"]== \"TRAIN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test_filtered[\"topics\"]\n",
    "y_train = y_train_filtered[\"topics\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape, X_train.shape, X_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
